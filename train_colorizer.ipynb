{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e53b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 1) Imports & CUDA Setup\n",
    "import os, glob, time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import STL10\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "cudnn.benchmark = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9960b360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing train (5000 images)…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train→64×64: 100%|██████████| 5000/5000 [00:05<00:00, 846.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing test (8000 images)…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test→64×64: 100%|██████████| 8000/8000 [00:09<00:00, 856.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# 2) On-Disk Preprocessing to 64×64 (run once)\n",
    "preproc_root = './data/preprocessed_64'\n",
    "resize64 = T.Resize((64,64))\n",
    "\n",
    "for split in ['train', 'test']:\n",
    "    dst = os.path.join(preproc_root, split)\n",
    "    os.makedirs(dst, exist_ok=True)\n",
    "    ds = STL10(root='./data', split=split, download=True)\n",
    "    print(f\"Preprocessing {split} ({len(ds)} images)…\")\n",
    "    for idx, (img, _) in enumerate(tqdm(ds, desc=f'{split}→64×64')):\n",
    "        out_path = os.path.join(dst, f'{idx:04d}.png')\n",
    "        if not os.path.exists(out_path):\n",
    "            resize64(img).save(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5831622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 5000 Test: 8000\n"
     ]
    }
   ],
   "source": [
    "# 3) Disk-Based Dataset (64×64)\n",
    "class Preproc64Dataset(Dataset):\n",
    "    def __init__(self, folder):\n",
    "        self.paths = sorted(glob.glob(f\"{folder}/*.png\"))\n",
    "        self.to_tensor = T.ToTensor()\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths[idx]).convert('RGB')\n",
    "        tgt = self.to_tensor(img)                                    # [3,64,64]\n",
    "        gray = T.functional.rgb_to_grayscale(img, 1)                  # PIL gray\n",
    "        inp  = self.to_tensor(gray)                                  # [1,64,64]\n",
    "        return inp, tgt\n",
    "\n",
    "train_ds = Preproc64Dataset(f'{preproc_root}/train')\n",
    "test_ds  = Preproc64Dataset(f'{preproc_root}/test')\n",
    "print(\"Train:\", len(train_ds), \"Test:\", len(test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ced9be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=16, shuffle=True,\n",
    "    num_workers=2, pin_memory=True, persistent_workers=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=16, shuffle=False,\n",
    "    num_workers=2, pin_memory=True, persistent_workers=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7c1c3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyColorizer(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ConvTranspose2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 5) TinyColorizer Model\n",
    "class TinyColorizer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        enc, ch = [], 1\n",
    "        for oc in [16,32,64,128]:\n",
    "            enc += [nn.Conv2d(ch,oc,3,padding=1), nn.ReLU(True), nn.BatchNorm2d(oc), nn.MaxPool2d(2)]\n",
    "            ch = oc\n",
    "        self.encoder = nn.Sequential(*enc)\n",
    "        dec = []\n",
    "        for oc in [64,32,16]:\n",
    "            dec += [nn.ConvTranspose2d(ch,oc,3,2,1,1), nn.ReLU(True), nn.BatchNorm2d(oc)]\n",
    "            ch = oc\n",
    "        dec += [\n",
    "            nn.ConvTranspose2d(ch,16,3,2,1,1), nn.ReLU(True), nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16,3,3,padding=1), nn.Sigmoid()\n",
    "        ]\n",
    "        self.decoder = nn.Sequential(*dec)\n",
    "    def forward(self,x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "model = TinyColorizer().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d109c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_23612\\1633008719.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler    = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# 6) Training Loop (5 epochs demo)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "scaler    = GradScaler()\n",
    "num_epochs, best_val, patience, wait = 5, float('inf'), 3, 0\n",
    "\n",
    "for ep in range(1, num_epochs+1):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for inp, tgt in train_loader:\n",
    "        inp, tgt = inp.to(device), tgt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            out = model(inp)\n",
    "            loss = criterion(out, tgt)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        running += loss.item() * inp.size(0)\n",
    "    train_loss = running / len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    vrun = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inp, tgt in test_loader:\n",
    "            inp, tgt = inp.to(device), tgt.to(device)\n",
    "            with autocast():\n",
    "                vrun += criterion(model(inp), tgt).item() * inp.size(0)\n",
    "    val_loss = vrun / len(test_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {ep}/{num_epochs}  Train: {train_loss:.4f}  Val: {val_loss:.4f}  Time: {time.time()-start:.1f}s\")\n",
    "\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        torch.save(model.state_dict(),'best_colorizer64.pt')\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951a3313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Quick Visual Check on 10 Samples\n",
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "samples = [test_ds[i] for i in range(0, len(test_ds), len(test_ds)//10)]\n",
    "fig, axes = plt.subplots(10,3, figsize=(6,20))\n",
    "for i,(inp,tgt) in enumerate(samples):\n",
    "    with torch.no_grad():\n",
    "        out = model(inp.unsqueeze(0).to(device))\n",
    "    out_img = out[0].cpu().permute(1,2,0).numpy()\n",
    "    tgt_img = tgt.permute(1,2,0).numpy()\n",
    "    gray_img= inp.squeeze(0).permute(1,2,0).numpy()\n",
    "    axes[i,0].imshow(gray_img, cmap='gray'); axes[i,0].set_title('Input'); axes[i,0].axis('off')\n",
    "    axes[i,1].imshow(out_img);               axes[i,1].set_title('Predicted');axes[i,1].axis('off')\n",
    "    axes[i,2].imshow(tgt_img);               axes[i,2].set_title('GroundTruth');axes[i,2].axis('off')\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
